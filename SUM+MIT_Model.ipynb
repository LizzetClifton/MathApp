{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SUM+MIT_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Sp-TNOa4sJ2v",
        "TO0TfM4SSFFr"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LizzetClifton/SUMMIT/blob/master/SUM%2BMIT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLPtAowKCWHN",
        "colab_type": "text"
      },
      "source": [
        "# SUM+MIT CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxxgFk68P4H4",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains the training for the model, and the corresponding predictions, with the clean datasets. \n",
        "\n",
        "Upload \"inverted_df\" and \"inverted_test_df\" before running. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKMvJ-juqNFo",
        "colab_type": "text"
      },
      "source": [
        "## CNN for Numbers & Symbols"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yC46RauFzeoC",
        "colab": {}
      },
      "source": [
        "# Import all necessary packages\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "#from zipfile import ZipFile\n",
        "from sklearn.datasets import load_files\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import cv2\n",
        "import math\n",
        "import imageio\n",
        "import numpy as np\n",
        "import os \n",
        "from keras.preprocessing.image import img_to_array\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5FelvskzeoI",
        "colab": {}
      },
      "source": [
        "# Additional imports\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JxEVrg1KzeoJ",
        "colab": {}
      },
      "source": [
        "# read in clean datasets\n",
        "train_math = pd.read_csv('inverted_df.csv')\n",
        "test_math = pd.read_csv('inverted_test_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeJMlesTwYxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to turn df into tensorflow dataset\n",
        "def tfDataset(math_dataset):\n",
        "  tf.enable_eager_execution()\n",
        "\n",
        "  # making a new list for columns so that they can be ints\n",
        "  # and the target can be a string\n",
        "  new_list = list(range(784))\n",
        "  new_list.append('Target')\n",
        "\n",
        "  # Used to be train symbols\n",
        "  math_dataset.columns = new_list\n",
        "  features = list(range(784))\n",
        "  \n",
        "  # Create tf training dataset\n",
        "  dataset = (\n",
        "      tf.data.Dataset.from_tensor_slices(\n",
        "          (\n",
        "              tf.cast(math_dataset[features].values, tf.float32),\n",
        "              tf.cast(math_dataset['Target'].values, tf.int32)\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM6_DfYKw4LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn train and test dataframes into tf datasets\n",
        "training_dataset = tfDataset(train_math)\n",
        "testing_dataset = tfDataset(test_math)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vZFi8noiycu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the class names\n",
        "# These are the real class names, not the ones we mapped to numbers\n",
        "class_names = ['0', '1', '2', '3', '4', '5','6','7','8','9','-','+','times','div']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-0EJAqfthLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check number of training and testing examples\n",
        "num_train_examples = len(train_math)\n",
        "num_test_examples = len(test_math)\n",
        "\n",
        "print(num_train_examples, num_test_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6AaNgz5KxBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function will reshape each element in the tensor\n",
        "# from [784] array to [28,28,1] array\n",
        "def reshape(images, labels):\n",
        "  images = tf.reshape(images, (28,28,1))\n",
        "  return images, labels\n",
        "\n",
        "# The map function applies the reshaping function to each element in the train\n",
        "# and test datasets\n",
        "training_dataset =  training_dataset.map(reshape)\n",
        "testing_dataset  =  testing_dataset.map(reshape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2MkCSNMiyKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are reshaping and viewing 25 of the images from our dataset\n",
        "plt.figure(figsize=(10,10))\n",
        "i = 0\n",
        "\n",
        "for (image, label) in testing_dataset.take(25):\n",
        "    image = image.numpy().reshape((28,28))\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.xlabel(class_names[label])\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp-TNOa4sJ2v",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_TwscXjiyIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    # create first convolutional layer, with 3x3 filter and ReLu activation\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    # Perform max pooling with 2x2 matrix\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(14,  activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_vdzROGsK11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfJdr_EHsLgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "# Shuffle() will allocate a buffer of size of the number of training examples\n",
        "# for picking random entries. Repeat() will re-initialize the dataset once all\n",
        "# examples have been taken. Finally, batch() creates batches of the dataset with\n",
        "# batch size given as batch_size which is also the length of the batches\n",
        "train_dataset = training_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = testing_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dC8mP0bQObC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"folder_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                save_weights_only = True,\n",
        "                                                verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB3RUE9bsLdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "# .ceil() rounds number up to nearest integer\n",
        "model.fit(train_dataset, epochs=5, \n",
        "          steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE), \n",
        "          callbacks = [cp_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO0TfM4SSFFr",
        "colab_type": "text"
      },
      "source": [
        "### Let's evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUFEl0z7sLbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zCwzGSxQtom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "loss, acc = model.evaluate(test_dataset, steps = math.ceil(num_test_examples/32))\n",
        "print('Restored model accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgHalP-JRA9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model\n",
        "model.save(\"cnn.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZwywYPKcjL1",
        "colab_type": "text"
      },
      "source": [
        "### Loading model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YonbBb88cn0H",
        "colab_type": "text"
      },
      "source": [
        "If you have already run the code up to here once in another session, then you should have saved a cnn.h5 file. If you already have that, you can skip the cells under \"Build the Model\" and \"Let's evaluate accuracy\" and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYg9H6NcE8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = tf.keras.models.load_model('cnn.h5')\n",
        "new_model.summary()\n",
        "BATCH_SIZE = 32\n",
        "test_dataset = testing_dataset.batch(BATCH_SIZE)\n",
        "loss, acc = new_model.evaluate(test_dataset, steps = math.ceil(num_test_examples/32))\n",
        "print('Restored model accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C9Hr-goCCIKi"
      },
      "source": [
        "## Let's make some predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5flWnX0jCIKg",
        "colab": {}
      },
      "source": [
        "# Get the first prediction\n",
        "for test_images, test_labels in test_dataset.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IpRnkaihCIKc",
        "colab": {}
      },
      "source": [
        "type(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4EDyBwSLCIKW"
      },
      "source": [
        "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "05wKXf6wCIKU",
        "colab": {}
      },
      "source": [
        "# Prediction probabilities for each target\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aTWaK1meCIKT"
      },
      "source": [
        "A prediction is an array of 14 numbers. These describe the \"confidence\" of the model that the image corresponds to each of the 14 different elements in the dataset (10 digits, 4 symbols). We can see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JvRdOG7WCIKQ",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXHfPMHpCIKQ"
      },
      "source": [
        "So the model is most confident that this image is a 9 or `class_names[8]`. And we can check the test label to see this is correct:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kE2_93XVCIKM",
        "colab": {}
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8zphbyaNCIKJ"
      },
      "source": [
        "We can graph this to look at the full set of 14 class predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OwBcftN8CIKE",
        "colab": {}
      },
      "source": [
        "def plot_image(i, predictions_array, true_labels, images):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NkeI068iCIKD"
      },
      "source": [
        "Let's look at the first image, predictions, and prediction array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yER-Q255CIJ5",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hOPnzj1ZCIJ2"
      },
      "source": [
        "Let's plot several images with their predictions. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percent (out of 100) for the predicted label. Note that it can be wrong even when very confident. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SFx9CM4LCIJs",
        "colab": {}
      },
      "source": [
        "# Plot the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-rBHVzsC1aJ",
        "colab_type": "text"
      },
      "source": [
        "You now have a trained model and you can download the .h5 model file."
      ]
    }
  ]
}